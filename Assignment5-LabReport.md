**SENG 438- Software Testing, Reliability, and Quality**

**Lab. Report \#5 â€“ Software Reliability Assessment**

| Group \#:       | G38  |
|-----------------|---|
| Student Names:  | Tony Vo, Chace Nielson, Chad Holst, Olisehemeka Chukwuma |

- [1 Introduction](#introduction)

- [2 Assessment Using Reliability Growth Testing](#assessment-using-reliability-growth-testing)

- [3 Assessment Using Reliability Demonstration Chart](#assessment-using-reliability-demonstration-chart)

- [4 Comparison of Results](#comparison-of-results)

- [5 Discussion on Similarity and Differences of the Two Techniques](#discussion-on-similarity-and-differences-of-the-two-techniques)

- [6 How the team work/effort was divided and managed](#how-the-team-workeffort-was-divided-and-managed)

- [7 Difficulties encountered, challenges overcome, and lessons learned](#difficulties-encountered-challenges-overcome-and-lessons-learned)

- [8 Comments/feedback on the lab itself](#commentsfeedback-on-the-lab-itself)

# Introduction
In this assignment, we were given failure data of a theoretical software system under test. The failure data is given in a comma-separated value (CSV) format, with five columns pertaining to each failure event: the time interval of the failure, the failure count, the execution time of the system measured in hours, the failure identification work measured in person-hours, and the computer time failure identification measured in hours. The objective of this assignment is to use two methods: reliability growth testing and reliability assessment using a Reliability Demonstration Chart (RDC) to analyze integration test data. 

To do so, we were also instructed to use several tools to perform the analysis: Covariate Software Failure and Reliability Assessment Tool (C-SFRAT), Computer-Aided Software Reliability Estimation (CASRE) tool, RDC-11, and SRTAT (a tool created by Dr. Far and his team). From these tools, we manipulated the failure dataset to ensure that the data is valid for the tools that we chose to use. From there, we were able to produce output by selecting and entering parameters, and consequently, use the results to interpret the data.
 
Before this assignment, none of our group members had any experience with software reliability testing. As such, this lab provided our group with several tools to understand the reliability of a theoretical software system using reliability growth testing and a RDC.

# Assessment Using Reliability Growth Testing 

# Assessment Using Reliability Demonstration Chart 

# 

# Comparison of Results

# Discussion on Similarity and Differences of the Two Techniques
Both techniques are based on inter failure times. However, the difference is that RDC is always also based on a target failure rate. Reliability growth analysis can be based on failure count and failure rate instead of just inter failure times. We learned that inter failure times are quite useful when evaluating the reliability of a SUT. 

RDT is used more for demonstrating the reliability of a product and performs at the system level. It usually is set up as a success test. RGT is used more in data collection and for factors from the field. It is used in collection, modelling, analysis and interpretation of data.

# How the team work/effort was divided and managed
In this assignment, each member of the group started off by learning how the tools worked and the specifications of the lab. After that, we worked as a team to understand and accomplish the rest of the lab's tasks. Although this lab appeared to be shorter than the previous labs, we had trouble accomplishing the goals given in the assignment document. We had two team members working on Part I, and another two team members working on Part II. Occasionally, we would switch responsibilities and work on other parts of the lab since we frequently ran into trouble with understanding the tools, data, and specifications of this lab.

# Difficulties encountered, challenges overcome, and lessons learned
Our main difficulty was in understanding how this lab's tools worked. We found it difficult to find documentation, so we had to manually manipulate the given data. The tools the lab used were very new to each member of the group so it required a lot of effort and time to begin to understand the components of the assignment. The tools were very challenging to use and took a lot of time to understand. The group was eventually able to learn how to use the tools and implement the solutions to the assignment problems after a considerable amount of time.

# Comments/feedback on the lab itself
The lab was difficult to understand. We felt it gave the basics of the material and left us to learn and understand what to do on our own. It would have been helpful to have more documentation or at least links to the documentation of the tools. Furthermore, we found it difficult to do the Laplace test. Although we found formulas online and in the slides, there were not many tools available online that would allow us to check our results to know if our Excel formula was correct. Once we were able to understand what the lab was asking us to do and also how the tools worked we were able to make some progress. 

The lab provided some insight into using data to determine the reliability of a software under test. In doing this assignment, we learned that the field of Software Testing, Reliability, and Quality can be complicated and may require a multitude of tools to interpret the data. We were able to gain some insight as to how things might work in a professional environment.
